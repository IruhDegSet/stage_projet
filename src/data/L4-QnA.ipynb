{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# LangChain: Q&A over Documents\n",
    "\n",
    "An example might be a tool that would allow you to query a product catalog for items of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c1f7b9",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "#pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "height": 96,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5f98b405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead635a0-42e2-46cc-a9f7-98419eceae6d",
   "metadata": {},
   "source": [
    "Note: LLM's do not always produce the same results. When executing the code in your notebook, you may get slightly different answers that those in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {
    "height": 130
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.document_loaders import CSVLoader, TextLoader\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch, Chroma\n",
    "from IPython.display import display, Markdown\n",
    "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings, FastEmbedEmbeddings\n",
    "from langchain_community import embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "eeffd684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>fournisseur</th>\n",
       "      <th>description</th>\n",
       "      <th>marque</th>\n",
       "      <th>prix</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41575</th>\n",
       "      <td>FSP:GD5S60Z00DESV6</td>\n",
       "      <td>macle</td>\n",
       "      <td>SP 5Y OS 9X5 4H RT</td>\n",
       "      <td>fujitsu</td>\n",
       "      <td>1584.00</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265881</th>\n",
       "      <td>TS-464-8G</td>\n",
       "      <td>Ingram</td>\n",
       "      <td>TS-464-8G 4BAY 8GBDDR4 2X2.5GBE</td>\n",
       "      <td>qnap</td>\n",
       "      <td>630.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11669</th>\n",
       "      <td>D-DDR4-4GB-007</td>\n",
       "      <td>convena</td>\n",
       "      <td>ProXtend 4GB DDR4 PC4-21300 2666MHz</td>\n",
       "      <td>proxtend</td>\n",
       "      <td>22.07</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231168</th>\n",
       "      <td>46372</td>\n",
       "      <td>PCA</td>\n",
       "      <td>Fibre optique Duplex LC / LC OM3 3m</td>\n",
       "      <td>lindy</td>\n",
       "      <td>7.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256239</th>\n",
       "      <td>21.15.3941</td>\n",
       "      <td>Secomp</td>\n",
       "      <td>Cordon ROLINE Data Center SLIM, UTP Cat6A/Cl.E...</td>\n",
       "      <td>roline</td>\n",
       "      <td>0.86</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        part fournisseur  \\\n",
       "41575     FSP:GD5S60Z00DESV6       macle   \n",
       "265881  TS-464-8G                 Ingram   \n",
       "11669         D-DDR4-4GB-007     convena   \n",
       "231168                 46372         PCA   \n",
       "256239            21.15.3941      Secomp   \n",
       "\n",
       "                                              description  \\\n",
       "41575                                  SP 5Y OS 9X5 4H RT   \n",
       "265881                    TS-464-8G 4BAY 8GBDDR4 2X2.5GBE   \n",
       "11669                 ProXtend 4GB DDR4 PC4-21300 2666MHz   \n",
       "231168                Fibre optique Duplex LC / LC OM3 3m   \n",
       "256239  Cordon ROLINE Data Center SLIM, UTP Cat6A/Cl.E...   \n",
       "\n",
       "                      marque     prix  quantity  \n",
       "41575                fujitsu  1584.00        50  \n",
       "265881  qnap                   630.74         1  \n",
       "11669               proxtend    22.07         3  \n",
       "231168                 lindy     7.05         1  \n",
       "256239                roline     0.86       749  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file = 'data_base.csv'\n",
    "df= pd.read_csv(file, encoding='utf-8')\n",
    "data= df.sample(1000, random_state=42)\n",
    "data.to_csv('sample_db.csv', index=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "00d19be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean       59.882000\n",
       "std        58.696246\n",
       "min         1.000000\n",
       "25%        29.000000\n",
       "50%        38.500000\n",
       "75%        63.000000\n",
       "max       255.000000\n",
       "Name: description, dtype: float64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['description'].apply(str).apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "11fd54af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to txt\n",
    "columns= data.columns\n",
    "doc = '\\n'.join([' '.join([f\"{col}: {str(row[col]).strip(' ').strip('\\n')}\" for col in columns]) for idx, row in data.iterrows()])\n",
    "f= open('sample_db.txt', 'w')\n",
    "f.write(doc)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "749ab23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151.5556\n",
      "79\n",
      "367\n",
      "134.0\n"
     ]
    }
   ],
   "source": [
    "lengths= []\n",
    "for line in doc.split('\\n'):\n",
    "    lengths.append(len(line))\n",
    "import numpy as np\n",
    "print(np.mean(lengths))\n",
    "print(np.min(lengths))\n",
    "print(np.max(lengths))\n",
    "print(np.median(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7249846e",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# load txt file\n",
    "file= 'sample_db.txt'\n",
    "loader = TextLoader(file_path=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "be533f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbd_model= HuggingFaceInferenceAPIEmbeddings(api_key='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', model_name='intfloat/multilingual-e5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5bfaba30",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c5b3102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, TextSplitter\n",
    "r_splitter= RecursiveCharacterTextSplitter(chunk_size= 100, chunk_overlap= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14305d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=Chroma,\n",
    "    text_splitter= r_splitter,\n",
    "    embedding= mbd_model,\n",
    "    vectorstore_kwargs= {'persist_directory': 'test_chroma'}\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a4c615-d6e4-4dd6-bc53-a9c46df7276c",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "- The notebook uses `langchain==0.0.179` and `openai==0.27.7`\n",
    "- For these library versions, `VectorstoreIndexCreator` uses `text-davinci-003` as the base model, which has been deprecated since 1 January 2024.\n",
    "- The replacement model, `gpt-3.5-turbo-instruct` will be used instead for the `query`.\n",
    "- The `response` format might be different than the video because of this replacement model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cfd0cc37",
   "metadata": {
    "height": 113
   },
   "outputs": [],
   "source": [
    "llm_replacement_model = ChatGroq(temperature=1, \n",
    "                               model='llama3-8b-8192',\n",
    "                               groq_api_key='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')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "33f02e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are the descriptions:\n",
       "\n",
       "1. KNIPEX Couteau pour Câble\n",
       "2. KNIPEX Pince à préhension frontale\n",
       "3. One pour All Grundig Télécommande"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query =\"listez 10 marques les plus frequentes\"\n",
    "response = index.query(query, \n",
    "                       llm = llm_replacement_model)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae21f1ff",
   "metadata": {
    "height": 30,
    "scrolled": true
   },
   "source": [
    "Here is finished"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2534597e-4b0c-4563-a208-e2dd91064438",
   "metadata": {},
   "source": [
    "## Step By Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631396c6",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "loader = CSVLoader(file_path=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2164b5",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a977f44",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e875693a",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779bec75",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "embed = embeddings.embed_query(\"Hi my name is Harrison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699aaaf9",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(len(embed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d00d346",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(embed[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad0bb0",
   "metadata": {
    "height": 96
   },
   "outputs": [],
   "source": [
    "db = DocArrayInMemorySearch.from_documents(\n",
    "    docs, \n",
    "    embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0329bfd5",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "query = \"Please suggest a shirt with sunblocking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7909c6b7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "docs = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43321853",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eba90b5",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c3596e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0625f5e8",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature = 0.0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a573f58a",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "qdocs = \"\".join([docs[i].page_content for i in range(len(docs))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14682d95",
   "metadata": {
    "height": 79
   },
   "outputs": [],
   "source": [
    "response = llm.call_as_llm(f\"{qdocs} Question: Please list all your \\\n",
    "shirts with sun protection in a table in markdown and summarize each one.\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bba545b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c94d22",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4769316",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "query =  \"Please list all your shirts with sun protection in a table \\\n",
    "in markdown and summarize each one.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc3c2f3",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "response = qa_stuff.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba1a5db",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500ec062",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "response = index.query(query, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cffb19f",
   "metadata": {
    "height": 96
   },
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch,\n",
    "    embedding=embeddings,\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b325340f-26b4-4c7e-81da-da4b895ae058",
   "metadata": {},
   "source": [
    "Reminder: Download your notebook to you local computer to save your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b58916",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d590b337",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cb587c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec249f1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d64f166",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21322e7e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
